{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Attention Seeker \u2013 Data Analysis Notebook\n", "\n", "This notebook performs exploratory data analysis (EDA), correlation analysis, and baseline machine learning models\n", "using the preprocessed dataset (`attention_scores.csv`) generated by the pipeline notebook.\n"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["import pandas as pd\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.linear_model import LinearRegression, LogisticRegression\n", "from sklearn.metrics import r2_score, mean_absolute_error, accuracy_score, f1_score, roc_auc_score, roc_curve\n", "\n", "%matplotlib inline\n"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["df = pd.read_csv(\"attention_scores.csv\")\n", "print(\"Data shape:\", df.shape)\n", "df.head()\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Basic Dataset Overview\n", "\n", "We inspect column names, data types, and basic statistics to understand the structure of the processed dataset."]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["print(df.dtypes)\n", "df.describe().T\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Missing Values\n", "\n", "Check for missing values in each feature."]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["df.isna().mean().sort_values(ascending=False)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Distributions of Key Variables\n", "\n", "We visualize the distribution of the Attention Score and Outside Factors to understand their ranges and skew."]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n", "\n", "if 'attention_score' in df.columns:\n", "    axes[0].hist(df['attention_score'], bins=40)\n", "    axes[0].set_title(\"Attention Score Distribution\")\n", "    axes[0].set_xlabel(\"Attention Score\")\n", "\n", "if 'outside_factors' in df.columns:\n", "    axes[1].hist(df['outside_factors'], bins=40)\n", "    axes[1].set_title(\"Outside Factors Distribution\")\n", "    axes[1].set_xlabel(\"Outside Factors Score\")\n", "\n", "plt.tight_layout()\n", "plt.show()\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Correlation Between Attention Score and Outside Factors\n", "\n", "We compute Pearson's correlation coefficient between the Attention Score and Outside Factors to measure\n", "whether healthier routines are associated with higher attention."]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["if {'attention_score', 'outside_factors'}.issubset(df.columns):\n", "    corr = df['attention_score'].corr(df['outside_factors'])\n", "    print(\"Pearson correlation (Attention vs Outside Factors):\", corr)\n", "\n", "    plt.figure(figsize=(6, 5))\n", "    sns.scatterplot(x='outside_factors', y='attention_score', data=df, alpha=0.4)\n", "    plt.title(f\"Attention Score vs Outside Factors (r = {corr:.3f})\")\n", "    plt.xlabel(\"Outside Factors\")\n", "    plt.ylabel(\"Attention Score\")\n", "    plt.show()\n", "else:\n", "    print(\"Required columns 'attention_score' and 'outside_factors' not found.\")\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Feature Correlation Heatmap\n", "\n", "We generate a correlation matrix for numeric features to inspect linear relationships among features\n", "and the Attention Score."]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["num_df = df.select_dtypes(include=[np.number])\n", "\n", "plt.figure(figsize=(10, 8))\n", "sns.heatmap(num_df.corr(), annot=False, cmap=\"coolwarm\", center=0)\n", "plt.title(\"Correlation Heatmap (Numeric Features)\")\n", "plt.show()\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Regression Model: Predicting Attention Score\n", "\n", "We fit a baseline linear regression model to predict the Attention Score using engineered features\n", "such as normalized HR, HRV, movement, and Outside Factors."]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["candidate_features = [\n", "    'hr_norm', 'hrv_norm', 'movement_norm',\n", "    'outside_factors'\n", "]\n", "\n", "feature_cols = [c for c in candidate_features if c in df.columns]\n", "print(\"Using features:\", feature_cols)\n", "\n", "if 'attention_score' not in df.columns:\n", "    raise ValueError(\"Column 'attention_score' not found in dataframe.\")\n", "\n", "X = df[feature_cols].values\n", "y = df['attention_score'].values\n", "\n", "X_train, X_test, y_train, y_test = train_test_split(\n", "    X, y, test_size=0.25, random_state=42\n", ")\n", "\n", "reg = LinearRegression()\n", "reg.fit(X_train, y_train)\n", "\n", "y_pred = reg.predict(X_test)\n", "r2 = r2_score(y_test, y_pred)\n", "mae = mean_absolute_error(y_test, y_pred)\n", "\n", "print(f\"Linear Regression R^2: {r2:.4f}\")\n", "print(f\"Linear Regression MAE: {mae:.4f}\")\n"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["plt.figure(figsize=(6, 5))\n", "plt.scatter(y_test, y_pred, alpha=0.4)\n", "plt.xlabel(\"True Attention Score\")\n", "plt.ylabel(\"Predicted Attention Score\")\n", "plt.title(\"Regression: True vs Predicted Attention Score\")\n", "line_min = min(y_test.min(), y_pred.min())\n", "line_max = max(y_test.max(), y_pred.max())\n", "plt.plot([line_min, line_max], [line_min, line_max], 'r--')\n", "plt.tight_layout()\n", "plt.show()\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Classification Model: Detecting Attention Lapses\n", "\n", "We construct a binary label representing an attention lapse and train a Logistic Regression classifier\n", "to detect such events based on the same set of features."]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["lapse_threshold = -0.05\n", "df['lapse'] = (df['attention_score'] < lapse_threshold).astype(int)\n", "\n", "X_cls = df[feature_cols].values\n", "y_cls = df['lapse'].values\n", "\n", "Xc_train, Xc_test, yc_train, yc_test = train_test_split(\n", "    X_cls, y_cls, test_size=0.25, random_state=42, stratify=y_cls\n", ")\n", "\n", "clf = LogisticRegression(max_iter=1000)\n", "clf.fit(Xc_train, yc_train)\n", "\n", "yc_pred = clf.predict(Xc_test)\n", "yc_proba = clf.predict_proba(Xc_test)[:, 1]\n", "\n", "acc = accuracy_score(yc_test, yc_pred)\n", "f1 = f1_score(yc_test, yc_pred)\n", "try:\n", "    auc = roc_auc_score(yc_test, yc_proba)\n", "except ValueError:\n", "    auc = float('nan')\n", "\n", "print(f\"Logistic Regression Accuracy: {acc:.4f}\")\n", "print(f\"Logistic Regression F1: {f1:.4f}\")\n", "print(f\"Logistic Regression ROC-AUC: {auc:.4f}\")\n"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["fpr, tpr, thresh = roc_curve(yc_test, yc_proba)\n", "plt.figure(figsize=(6, 5))\n", "plt.plot(fpr, tpr, label=f\"ROC (AUC = {auc:.3f})\")\n", "plt.plot([0, 1], [0, 1], 'k--', label=\"Random\")\n", "plt.xlabel(\"False Positive Rate\")\n", "plt.ylabel(\"True Positive Rate\")\n", "plt.title(\"ROC Curve - Attention Lapse Classifier\")\n", "plt.legend()\n", "plt.tight_layout()\n", "plt.show()\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Conclusions\n", "\n", "- The engineered Attention Score behaves as a meaningful summary of physiological engagement.\n", "- Outside Factors can be related to attention trends via correlation analysis.\n", "- Baseline linear and logistic regression models demonstrate that attention and lapses\n", "  can be predicted from wearable-derived features, supporting the feasibility of\n", "  real-time attention monitoring in a future Apple Watch application.\n"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 5}